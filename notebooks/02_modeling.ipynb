{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d23715",
   "metadata": {},
   "source": [
    "# DESAFIO CIENTISTA DE DADOS - INDICIUM\n",
    "\n",
    "Participante: João Pedro Coelho Barbosa\n",
    "\n",
    "### Nesse desafio vamos explorar de forma analítica um **Dataset** constando dados acerca da produção, faturamento e avaliação de filmes no IMDB com intuito de elaborar um algoritmo de predição de notas no IMDB\n",
    "> Neste **Notebook** iremos abordar tópicos importantes acerca da modelagem do algoritmo de Machine Learning:\n",
    ">>- Modelagem dos dados de treino e teste e Engenharia de Features _(Feature Engineering)_\n",
    ">>- Validação dos modelos\n",
    ">>- Otimização de hiper parâmetros \n",
    ">>- Escolha do modelo final para predição envolvendo o **Dataset `desafio_indicium_imdb.csv `**\n",
    "---\n",
    "### Principais desafios encontrados na Modelagem:\n",
    "1.  Engenharia de Features:\n",
    "- A modelagem dos dados para inserção nos modelos foi o principal desafio encontrado nessa jornada \n",
    "\n",
    "- Visto que, das 16 colunas do dataset original temos 5 numéricas, com as outras colunas constando o título do filme, onde não agregam de forma concisa nas features do modelo, além dessas também temos a classificação indicativa, os gêneros, o diretor e as estrelas que atuaram no filme.\n",
    "\n",
    "- Com isso, a meta girou em torno de buscar formas de criar features para modelos constando a relevância dos diretores e atores presentes na base\n",
    "\n",
    "- Técnicas como `OneHotEnconder` e `get_dummies` buscam expandir colunas categóricas de forma a agregar peso às features do modelo, transformando tais variáveis em diversas outras colunas booleanas de modo a apontar a categoria daquele dado de forma numérica, visto que os algoritmos \"só entendem\" números\n",
    "\n",
    "- Todavia, o grande número de combinações de gêneros (mais de 170 combinações), de diretores (mais de 400) e atores (mais de 1900) presentes na base tornaria inviável aplicar tais técnicas, já que seria criado um grande número de features aos dados de treino e teste do modelo, fazendo com que ao invés do modelo generalizar e entender os dados, fortalecendo suas predições, o modelo iria somente decorar os dados causando `overfitting`\n",
    "\n",
    "- Então criou 3 funções diferentes com foco em tratar esses dados:\n",
    "    - `fe_genre`: Esta função cria colunas com variáveis boolenas (1 e 0 - Pertence ou não pertence ao gênero) para cada gênero presente nas combinações, reduzindo o total de 172 combinações de gênero para 21 gêneros e no caso, 21 colunas de gênero, onde ao invés de ter uma coluna que conste todos os gêneros de um filme, teremos colunas com 1 para os gêneros em que aquele filme pertence e colunas com 0 para os que aquele filme não pertecem, agregando informações de gêneros ao modelo\n",
    "\n",
    "    - `fe_directors`: Como temos 402 diretores diferentes, temos que buscar alguma lógica que agregue informação do peso daquele diretor na qualidade do filme que ele dirige, assim apartir das colunas `Meta_score` e `No_of_votes` (Duas colunas com melhor correlação com a `IMDB_Rating`), criou-se TopNs, ou seja, buscou-se classificar cada diretor por quão bem ele é avaliado no Meta Score e quantidade de votos médio de seus filmes, visando entender também, sua popularidade e assim, ao invés de criar 400 colunas booleanas relacionando diretores aos seus filmes, criou-se colunas booleanas Top10, Top25 e Top50 indicando se aquele filme é dirigido por um diretor dentro daquele escopo TopN levantado, agregando a importância do diretor apartir do quão bem avaliado e popular frente à crítica ele é\n",
    "\n",
    "    - `fe_actors`: Seguiu-se a mesma lógica por trás da `fe_director`, todavia como o dataset apresenta 4 colunas diferentes para atores constando as 4 estrelas principais do filme, onde, por exemplo, um mesmo ator pode aparecer com a principal estrela em um filme e segunda principal estrela de outro, torna-se necessário levantar individualmente cada ator concatenando essas colunas com um `.groupby()` utilizando as métricas `Meta_score` e `No_of_votes` e só em seguida levantar os Top10, Top25 e Top50 de cada uma\n",
    "\n",
    "    > Uma outra abordagem interessante, mas que poderia induzir um **overfitting** seria avaliar da mesma forma, porém com o impacto de cada ator em cada posição de protagonismo num filme\n",
    "    >> Por exemplo: Marlon Brando pode ter filmes super bem avaliados sendo o protagonista do filme, entretando como estrela secundária e terciária sua média de notas pode ser diferentes. Todavia, um nível de detalhismo muito grande e grande agregações de variável costuma tender a modelos com overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "2. Escolha dos modelos\n",
    "- Para este desafio utilizamos três modelos principais:\n",
    "    - Um Baseline - Regressão Linear:\n",
    "    >Modelo clássico de predição que busca encontrar uma reta que generalize a distribuição dos dados, utiliza um algoritmo iterativo que busca encontrar a menor soma das distâncias dos para a reta, quando tratamos de multidimensionalidade esse conceito se torna mais \"abstrato\" mas sua funcionalidade ainda é muito útil, tornando bastante usado como **_Baseline_** para estudo de predição.\n",
    "            ![](https://imgur.com/t1admTB.png)\n",
    "    - Um algoritmo de Bagging - Random Forest Regressor:\n",
    "    >Bagging vem de *Bootstrap Aggregating*:\n",
    "    >>- Bootstrap = criar várias amostras diferentes dos dados originais (com reposição).\n",
    "    >>- Aggregating = juntar as previsões de todos os modelos (por média ou votação)\n",
    "            >>>**Funcionamento:**\n",
    "            >>>1. Temos o conjunto de dados inicial.\n",
    "            >>>2. Gera diversas amostras aleatórias com reposição a partir desse conjunto de dados.\n",
    "            >>>3. Para cada amostra aleatória gerada, treina um modelo diferente (uma árvore de decisão no nosso caso).\n",
    "            >>>4. Ao final, junta os resultados de todos os modelos. Como é uma classificação, o resultado será a votação da maioria.   \n",
    "            ![](https://i.imgur.com/EGDJjvk.png)\n",
    "    - Um algoritmo de Boosting - XGBoost Regressor:\n",
    "    >Boosting é uma técnica que vai aprendendo com erros dos preditores anteriores, ou seja, modelos simples que são treinados em sequência, onde cada um tenta corrigir os erros dos anteriores.:\n",
    "    >>- Bootstrap = criar várias amostras diferentes dos dados originais (com reposição).\n",
    "    >>- Aggregating = juntar as previsões de todos os modelos (por média ou votação)\n",
    "            >>>**Funcionamento:**\n",
    "            >>>1. Temos a base de dados inicial\n",
    "            >>>2. Treinamos o primeiro modelo\n",
    "            >>>3. Avaliamos onde ele errou\n",
    "            >>>4. Dá mais peso para os exemplos onde ele errou\n",
    "            >>>5. Treina o segundo modelo, porém focando em corrigir esses erros\n",
    "            >>>6. Repete o processo, até o total de modelos indicados (no nosso caso o número de árvores de decisão)\n",
    "            >>>7. Combina todas as previsões (Geralmente usando uma média ponderada ou soma com pesos) \n",
    "            ![](https://i.imgur.com/EGDJjvk.png)\n",
    "\n",
    "- Outros algoritmos especializados em predições:\n",
    "    - ARIMA _(AutoRegressive Integrated Moving Average)_ é um modelo clássico de séries temporais que captura tendências e padrões passados para prever valores futuros.\n",
    "    - SARIMA _(Seasonal ARIMA)_ é uma extensão do ARIMA que também leva em conta a sazonalidade, sendo ideal para dados com ciclos regulares, como vendas mensais ou produção de energia através de fontes intermitentes como solar e eólica.\n",
    "    - E algoritmos de _**Deep Learning**_ como LSTM _(Long Short-Term Memory)_ que busca \"memorizar\" valores antigos e sua influência em valores futuros\n",
    "\n",
    "---\n",
    "\n",
    "3. Métricas de Avaliação:\n",
    "- RMSE _(Root Mean Squared Error)_ ou Raiz Quadrada do Erro Quadrático Médio\n",
    "    - O RMSE mede a diferença média entre os valores previstos pelo modelo e os valores reais, penalizando erros maiores de forma mais intensa. Quanto menor o RMSE, melhor a performance do modelo.\n",
    "    **Fórmula:**  \n",
    "    $$\n",
    "    \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "    $$\n",
    "      \n",
    "    **Onde:**\n",
    "    - **$y_i$** = valor real da observação $i$\n",
    "    - **$\\hat{y}_i$** = valor previsto pelo modelo para a observação $i$\n",
    "    - **$n$** = número total de observações\n",
    "\n",
    "- R² _(Coeficiente de Determinação)_\n",
    "\n",
    "    - O R² indica a proporção da variabilidade dos dados que é explicada pelo modelo. Varia entre 0 e 1, sendo que valores mais próximos de 1 indicam que o modelo consegue explicar bem a variação dos dados.  \n",
    "    **Fórmula:**\n",
    "    $$\n",
    "    R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
    "    $$\n",
    "\n",
    "    **Onde:**\n",
    "    - **$y_i$** = valor real da observação $i$\n",
    "    - **$\\hat{y}_i$** = valor previsto pelo modelo para a observação $i$\n",
    "    - **$\\bar{y}$** = média dos valores reais\n",
    "    - **$n$** = número total de observações\n",
    "\n",
    "Em outras palavras:\n",
    "- RMSE baixo → previsões próximas aos valores reais.  \n",
    "- R² alto → modelo explica bem a variabilidade dos dados.\n",
    "\n",
    "---\n",
    "\n",
    "4. Otimização de Hiperparâmetros:\n",
    "- A Otimização de hiperparâmetros é um passo crucial na decisão final da escolha do modelo.\n",
    "- Para esse projeto, têm-se três modelos principais sendo estudados, o papel da otimização de hiperparâmetros é se utilizar de ténicas de validação, no caso deste estudo utilizou o `KFold`(Que se trata de uma téncnica de validação cruzada que foca em avaliar desempenho de diferentes modelos), e _pipelines_ de machine learning para avaliar qual a melhor configuração de hiperparâmetros para aqueles modelos.\n",
    "- Ela funciona iterando os modelos sob diferentes espaços de buscas de hiperparâmetros pré-definidas e avaliando as métricas abordadas acima, com foco em entender qual configuração atende às melhores métricas para aquele modelo\n",
    "    - O Algoritmo de otimização utilizado foi o `optuna`, onde precisamos definir a função `objective` que seria o \"objetivo de estudo\" do algoritmo de otimização\n",
    "    - É necessário definir o que também será a referência para a otimização, ou seja, o que será de fato otimizado, isto é, a métrica utilizada como base para ser otimizada e o sentido de sua otimização, por exemplo:\n",
    "    > Se utilizarmos o RMSE temos que buscar o sentido de minimização da métrica, tornando a menor e aumentando a proximidade dos valores previstos com os reais, se usarmos o R² temos que buscar o sentido de maximização da métrica, tornando a maior e aumentando a capacidade do modelo de generalizar a variabilidade dos dados\n",
    "    - Para esse caso, a melhor métrica e sentido de otimização é: Minimização do RMSE buscando ter modelos que estimem com o máximo de proximidade as notas do IMDB\n",
    "\n",
    "### Principais resultados\n",
    "\n",
    "### Tabela de Resultados dos Modelos\n",
    "\n",
    "| Modelo | R2 | RMSE |\n",
    "|:---|:---|:---|\n",
    "| LinearRegression | 0.5850 | 0.1864 |\n",
    "| RandomForest | 0.5947 | 0.1842 |\n",
    "| XGBoost | 0.5110 | 0.2024 |\n",
    "\n",
    "- RandomForest apresenta as melhores métricas e foi o modelo escolhido para o deploy em .pkl e predição da nota IMDB do filme Shawshank Redemption\n",
    "> Interessante abordar a versatilidade da clássica regressão linear, se destacando a frente do XGBoost e bem próximo ao RandomForest em questão de métricas\n",
    "---\n",
    "\n",
    "### Melhores Parâmetros dos Modelos\n",
    "\n",
    "| Modelo | Parâmetros |\n",
    "|:---|:---|\n",
    "| LinearRegression | `{'fit_intercept': True}` |\n",
    "| RandomForest | `{'n_estimators': 100, 'max_depth': 19, 'min_samples_leaf': 1}` |\n",
    "| XGBoost | `{'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.14}` |\n",
    "\n",
    "### Nota IMDB estimada para Shawshank Redemption e conclusões tiradas do estudo\n",
    "\n",
    "- O filme Shawshank Redemptio apresenta uma nota IMDB de 9.3, sendo a maior nota da história do site para um filme, se tratando claramente de um outlier que estava fora do escopo da base de treino e teste, fator que, de certo modo, não só dificulta a acertividade do modelo como praticamente impossibilita o modelo de prever tal valor, visto que, o modelo não \"faz ideia\" da possibilidade de uma nota desse valor já que ele aprendeu só até 9.2 que era o segundo maior valor de nota histórica dada pelo IMDB ao filme The Godfather\n",
    "- Todavia, o modelo previu uma nota de 8.8 para o filme, se tratando de uma nota ainda muito boa e bem destacada frente aos demais filme da base, pertencendo a um grupo seleto de notas que se encaixariam no top10 histórico de maiores notas ja dadas pelo IMDB. Então, de certo modo o modelo previu que o filme estaria dentro do top10 mais bem avaliados filmes na história do IMDB, um fator que reflete em si, também, na forma de tratamento de dados e criação de features realizada nesse estudo.\n",
    "> Um conclusão e ideia interessante seria tentar abordar topNs mais restritos para diretores e atores, como top5, top10 e por ai vai\n",
    "\n",
    "__Este foi um ótimo estudo onde pude abordar técnicas previamente estudadas acerca dos tópicos que envolvem a Ciência de Dados no geral, tive que ir atrás de alguns conhecimentos que não tinha de forma concreta para embasar o estudo e as conclusões que tirei acerca do mesmo. Empolgante a parte de explorar formas de criar novas features com foco em trazer uma capacidade de generalização maior ao modelo através dos dados.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd5cab7",
   "metadata": {},
   "source": [
    "## 1. Importação de bibliotecas e utilitários\n",
    "\n",
    "Este trecho de código importa bibliotecas, configurações e variáveis necessárias para a análise exploratória e processamento de dados.\n",
    "\n",
    "| Biblioteca | Função principal |\n",
    "|------------|-----------------|\n",
    "| **pandas** | Manipulação de dados em DataFrames |\n",
    "| **numpy** | Operações matemáticas e vetoriais |\n",
    "| **matplotlib.pyplot** | Visualizações gráficas básicas |\n",
    "| **seaborn** | Visualizações estatísticas mais elaboradas |\n",
    "| **sklearn.model_selection** | Divisão de dados, validação cruzada e busca de hiperparâmetros |\n",
    "| **sklearn.preprocessing** | Pré-processamento de dados (ex.: escalonamento, codificação) |\n",
    "| **sklearn.compose** | Transformações de colunas específicas via `ColumnTransformer` |\n",
    "| **sklearn.pipeline** | Criação de pipelines para modelagem e pré-processamento |\n",
    "| **sklearn.ensemble** | Modelos de ensemble, como Random Forest |\n",
    "| **sklearn.metrics** | Avaliação de modelos (ex.: RMSE, R²) |\n",
    "| **sklearn.linear_model** | Modelos lineares, como regressão linear |\n",
    "| **xgboost** | Modelos de boosting, como XGBRegressor |\n",
    "| **optuna** | Otimização de hiperparâmetros de forma automatizada |\n",
    "| **joblib** | Salvamento e carregamento de modelos treinados |\n",
    "| **functools.partial** | Criação de funções parciais para parametrização flexível |\n",
    "| **sys** | Configuração do path da pasta local e acesso a funcionalidades do sistema |\n",
    "| **src.eda_utils** | Arquivo de utilidades utilizado na EDA e na modelagem |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7f79d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import joblib\n",
    "from functools import partial\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "from src.eda_utils import conv_numerico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8d4b8b",
   "metadata": {},
   "source": [
    "## 2. Definindo o path e realizando a ingestão da base no script\n",
    "\n",
    "- Definindo o path do arquivo na pasta **/processed** buscando seguir as boas práticas de organização de diretórios\n",
    "- Leitura do **.csv** e conversão para um dataframe utilizando pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "75cd060f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_Title</th>\n",
       "      <th>Released_Year</th>\n",
       "      <th>Certificate</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Genre</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "      <th>Overview</th>\n",
       "      <th>Meta_score</th>\n",
       "      <th>Director</th>\n",
       "      <th>Star1</th>\n",
       "      <th>Star2</th>\n",
       "      <th>Star3</th>\n",
       "      <th>Star4</th>\n",
       "      <th>No_of_Votes</th>\n",
       "      <th>Gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>A</td>\n",
       "      <td>175</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>9.2</td>\n",
       "      <td>An organized crime dynasty's aging patriarch t...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>Marlon Brando</td>\n",
       "      <td>Al Pacino</td>\n",
       "      <td>James Caan</td>\n",
       "      <td>Diane Keaton</td>\n",
       "      <td>1620367</td>\n",
       "      <td>134966411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>UA</td>\n",
       "      <td>152</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>9.0</td>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>Heath Ledger</td>\n",
       "      <td>Aaron Eckhart</td>\n",
       "      <td>Michael Caine</td>\n",
       "      <td>2303232</td>\n",
       "      <td>534858444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>A</td>\n",
       "      <td>202</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The early life and career of Vito Corleone in ...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>Al Pacino</td>\n",
       "      <td>Robert De Niro</td>\n",
       "      <td>Robert Duvall</td>\n",
       "      <td>Diane Keaton</td>\n",
       "      <td>1129952</td>\n",
       "      <td>57300000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Series_Title  Released_Year Certificate  Runtime  \\\n",
       "0           The Godfather           1972           A      175   \n",
       "1         The Dark Knight           2008          UA      152   \n",
       "2  The Godfather: Part II           1974           A      202   \n",
       "\n",
       "                  Genre  IMDB_Rating  \\\n",
       "0          Crime, Drama          9.2   \n",
       "1  Action, Crime, Drama          9.0   \n",
       "2          Crime, Drama          9.0   \n",
       "\n",
       "                                            Overview  Meta_score  \\\n",
       "0  An organized crime dynasty's aging patriarch t...       100.0   \n",
       "1  When the menace known as the Joker wreaks havo...        84.0   \n",
       "2  The early life and career of Vito Corleone in ...        90.0   \n",
       "\n",
       "               Director           Star1           Star2          Star3  \\\n",
       "0  Francis Ford Coppola   Marlon Brando       Al Pacino     James Caan   \n",
       "1     Christopher Nolan  Christian Bale    Heath Ledger  Aaron Eckhart   \n",
       "2  Francis Ford Coppola       Al Pacino  Robert De Niro  Robert Duvall   \n",
       "\n",
       "           Star4  No_of_Votes        Gross  \n",
       "0   Diane Keaton      1620367  134966411.0  \n",
       "1  Michael Caine      2303232  534858444.0  \n",
       "2   Diane Keaton      1129952   57300000.0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/processed/data_cleaned.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04344ce",
   "metadata": {},
   "source": [
    "## 3. Definindo colunas categóricas, numéricas e para dropar do dataset\n",
    "- As colunas categóricas e numéricas tem foco em criar uma melhor organização e boas práticas para o momento do pré-processamento de dados\n",
    "- As colunas para dropar tem foco em limpar o dataset, preparando os dados para treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2d2e46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas numéricas e categóricas para pré-processamento e drop de colunas nos dados de treino e teste\n",
    "\n",
    "num_cols = ['Released_Year', 'Runtime', 'Meta_score', 'No_of_Votes','Gross']\n",
    "cat_cols = ['Certificate']\n",
    "drop_cols = ['Series_Title', 'Overview', 'Director', 'Star1', 'Star2', 'Star3', 'Star4', 'IMDB_Rating']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab6155",
   "metadata": {},
   "source": [
    "## 4. Função de _Feature Engineering_ para a coluna `Genre`\n",
    "- A função expande inicialmente a coluna de gênero em 3 diferentes colunas e seguida concatena elas em `generos`\n",
    "- Como alguns filmes apresentam só 1 ou 2 gêneros, exisitirão colunas com dados nulos\n",
    "- Logo mais é feito o drop desses dados nulos em `generos` e um `.strip()` seguido de um `.unique()` com a intenção de limpar os espaços vazios e buscar os valores únicos, ou seja, levantar todos os temas presentes na base e salvando em `generos_unicos`\n",
    "- Cria-se um loop para iterar `genero` em `generos_unicos` com a ideia de criar uma coluna para cada gênero\n",
    "- Assim foi-se criado novas 21 colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ddaab1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de gêneros únicos na base: 21\n",
      "\n",
      "Gêneros presentes na base:['Crime' 'Action' 'Biography' 'Drama' 'Western' 'Comedy' 'Adventure'\n",
      " 'Animation' 'Horror' 'Mystery' 'Film-Noir' 'Family' 'Romance' 'Sci-Fi'\n",
      " 'War' 'Music' 'Thriller' 'Musical' 'Fantasy' 'Sport' 'History']\n",
      "\n",
      "Shape do dataframe: (712, 35)\n",
      "\n",
      "Colunas do novo dataframe: Index(['Series_Title', 'Released_Year', 'Certificate', 'Runtime',\n",
      "       'IMDB_Rating', 'Overview', 'Meta_score', 'Director', 'Star1', 'Star2',\n",
      "       'Star3', 'Star4', 'No_of_Votes', 'Gross', 'Crime', 'Action',\n",
      "       'Biography', 'Drama', 'Western', 'Comedy', 'Adventure', 'Animation',\n",
      "       'Horror', 'Mystery', 'Film-Noir', 'Family', 'Romance', 'Sci-Fi', 'War',\n",
      "       'Music', 'Thriller', 'Musical', 'Fantasy', 'Sport', 'History'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_Title</th>\n",
       "      <th>Released_Year</th>\n",
       "      <th>Certificate</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "      <th>Overview</th>\n",
       "      <th>Meta_score</th>\n",
       "      <th>Director</th>\n",
       "      <th>Star1</th>\n",
       "      <th>Star2</th>\n",
       "      <th>...</th>\n",
       "      <th>Star4</th>\n",
       "      <th>No_of_Votes</th>\n",
       "      <th>Gross</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Action</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Western</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Adventure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>A</td>\n",
       "      <td>175</td>\n",
       "      <td>9.2</td>\n",
       "      <td>An organized crime dynasty's aging patriarch t...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>Marlon Brando</td>\n",
       "      <td>Al Pacino</td>\n",
       "      <td>...</td>\n",
       "      <td>Diane Keaton</td>\n",
       "      <td>1620367</td>\n",
       "      <td>134966411.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>UA</td>\n",
       "      <td>152</td>\n",
       "      <td>9.0</td>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>Heath Ledger</td>\n",
       "      <td>...</td>\n",
       "      <td>Michael Caine</td>\n",
       "      <td>2303232</td>\n",
       "      <td>534858444.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>A</td>\n",
       "      <td>202</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The early life and career of Vito Corleone in ...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>Al Pacino</td>\n",
       "      <td>Robert De Niro</td>\n",
       "      <td>...</td>\n",
       "      <td>Diane Keaton</td>\n",
       "      <td>1129952</td>\n",
       "      <td>57300000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>U</td>\n",
       "      <td>96</td>\n",
       "      <td>9.0</td>\n",
       "      <td>A jury holdout attempts to prevent a miscarria...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>Henry Fonda</td>\n",
       "      <td>Lee J. Cobb</td>\n",
       "      <td>...</td>\n",
       "      <td>John Fiedler</td>\n",
       "      <td>689845</td>\n",
       "      <td>4360000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>2003</td>\n",
       "      <td>U</td>\n",
       "      <td>201</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Gandalf and Aragorn lead the World of Men agai...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>Elijah Wood</td>\n",
       "      <td>Viggo Mortensen</td>\n",
       "      <td>...</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>1642758</td>\n",
       "      <td>377845905.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Series_Title  Released_Year Certificate  \\\n",
       "0                                  The Godfather           1972           A   \n",
       "1                                The Dark Knight           2008          UA   \n",
       "2                         The Godfather: Part II           1974           A   \n",
       "3                                   12 Angry Men           1957           U   \n",
       "4  The Lord of the Rings: The Return of the King           2003           U   \n",
       "\n",
       "   Runtime  IMDB_Rating                                           Overview  \\\n",
       "0      175          9.2  An organized crime dynasty's aging patriarch t...   \n",
       "1      152          9.0  When the menace known as the Joker wreaks havo...   \n",
       "2      202          9.0  The early life and career of Vito Corleone in ...   \n",
       "3       96          9.0  A jury holdout attempts to prevent a miscarria...   \n",
       "4      201          8.9  Gandalf and Aragorn lead the World of Men agai...   \n",
       "\n",
       "   Meta_score              Director           Star1            Star2  ...  \\\n",
       "0       100.0  Francis Ford Coppola   Marlon Brando        Al Pacino  ...   \n",
       "1        84.0     Christopher Nolan  Christian Bale     Heath Ledger  ...   \n",
       "2        90.0  Francis Ford Coppola       Al Pacino   Robert De Niro  ...   \n",
       "3        96.0          Sidney Lumet     Henry Fonda      Lee J. Cobb  ...   \n",
       "4        94.0         Peter Jackson     Elijah Wood  Viggo Mortensen  ...   \n",
       "\n",
       "           Star4 No_of_Votes        Gross  Crime  Action  Biography  Drama  \\\n",
       "0   Diane Keaton     1620367  134966411.0      1       0          0      1   \n",
       "1  Michael Caine     2303232  534858444.0      1       1          0      1   \n",
       "2   Diane Keaton     1129952   57300000.0      1       0          0      1   \n",
       "3   John Fiedler      689845    4360000.0      1       0          0      1   \n",
       "4  Orlando Bloom     1642758  377845905.0      0       1          0      1   \n",
       "\n",
       "   Western  Comedy  Adventure  \n",
       "0        0       0          0  \n",
       "1        0       0          0  \n",
       "2        0       0          0  \n",
       "3        0       0          0  \n",
       "4        0       0          1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fe_genre (df):\n",
    "    df[['Genre1', 'Genre2', 'Genre3']] = df['Genre'].str.split(',', expand=True)\n",
    "\n",
    "    generos = pd.concat([df['Genre1'], \n",
    "                        df['Genre2'], \n",
    "                        df['Genre3']])\n",
    "\n",
    "    # Dropando os valores NaN, removendo espaços em branco e pegando os valores únicos\n",
    "    generos_unicos = generos.dropna().str.strip().unique()\n",
    "    print(f\"Número de gêneros únicos na base: {len(generos_unicos)}\\n\")\n",
    "    print(f\"Gêneros presentes na base:{generos_unicos}\\n\")\n",
    "\n",
    "    # Criando colunas para cada gênero com variável booleana\n",
    "    for genero in generos_unicos:\n",
    "        df[genero] = df['Genre'].str.contains(genero, na=False).astype(int)\n",
    "\n",
    "    # Dropando as colunas 'Genre', 'Genre1', 'Genre2' e 'Genre3'\n",
    "    df_genres = df.drop(columns=['Genre', 'Genre1', 'Genre2', 'Genre3'])\n",
    "\n",
    "    # Shape do novo dataframe\n",
    "    print(f\"Shape do dataframe: {df_genres.shape}\\n\")\n",
    "    print(f\"Colunas do novo dataframe: {df_genres.columns}\\n\")\n",
    "\n",
    "    return df_genres\n",
    "\n",
    "# Visualizando o novo dataframe\n",
    "df_genre_vis = df.copy()\n",
    "visualizar_df_genre = fe_genre(df_genre_vis)\n",
    "visualizar_df_genre.iloc[:,:21].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d536c63",
   "metadata": {},
   "source": [
    "## 5. Função de _Feature Engineering_ para a coluna `Director`\n",
    "\n",
    "- Cria-se 2 listas\n",
    "    - Top50 diretores em média no Meta Score\n",
    "    - Top50 diretores em média de número de votos\n",
    "- Em seguida define-se uma função `criar_coluna_top_n` com foco em iterar sob as listas de top50s e extrair delas os top10, top25 e top50 melhores diretores para cada métrica\n",
    "- E assim itera cada diretor sob a ideia de verificar se ele esta ou não em cada uma dessas listas, se tiver preenche com 1 se não tiver, preenche com 0\n",
    "- Importante pontuar que, como são colunas geradas apartir de métricas extraídas de outras colunas, tais alterações devem ser feitas apos o `train_test_split()`, evitando _Data Leakage_ para os dados de teste\n",
    "> _Data Leakage_ é quando \"vazamos\" informações dos dados de treino para os dados de teste, fazendo com que o modelo \"pesque\" no dados de treino informaçoes que ele utilizará nos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d865d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe_directors(train_df, test_df):\n",
    "    top_n = [10, 25, 50]\n",
    "\n",
    "    # Criando listas com os 50 melhores diretores do treino\n",
    "    top50_dir_metascore = train_df.groupby('Director')['Meta_score'].mean().sort_values(ascending=False).head(50).index.tolist()\n",
    "    top50_dir_no_of_votes = train_df.groupby('Director')['No_of_Votes'].mean().sort_values(ascending=False).head(50).index.tolist()\n",
    "    #top50_dir_filmes = train_df['Director'].value_counts().head(50).index.tolist()\n",
    "\n",
    "    # Função para criar colunas booleanas no dataset\n",
    "    def criar_colunas_top_n(df, top_lists, top_n):\n",
    "\n",
    "        for n in top_n:\n",
    "            df[f'top{n}_dir_metascore'] = df['Director'].isin(top_lists['metascore'][:n]).astype(int)\n",
    "            df[f'top{n}_dir_no_of_votes'] = df['Director'].isin(top_lists['no_of_votes'][:n]).astype(int)\n",
    "            #df[f'top{n}_dir_filmes'] = df['Director'].isin(top_lists['filmes'][:n]).astype(int)\n",
    "\n",
    "    # Dicionário com listas top50\n",
    "    top_lists = {\n",
    "        'metascore': top50_dir_metascore,\n",
    "        'no_of_votes': top50_dir_no_of_votes,\n",
    "        #'filmes': top50_dir_filmes\n",
    "    }\n",
    "\n",
    "    # Criando as colunas no dataset de treino\n",
    "    criar_colunas_top_n(train_df, top_lists, top_n)\n",
    "\n",
    "    # Criando as colunas no dataset de teste\n",
    "    criar_colunas_top_n(test_df, top_lists, top_n)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526f7c3",
   "metadata": {},
   "source": [
    "## 6. Função de _Feature Engineering_ para as colunas `StarN`\n",
    "\n",
    "- Inicialmente, o código itera sobre cada uma das colunas de atores (`Star1`, `Star2`, `Star3`, `Star4`).\n",
    "- Para cada coluna, um DataFrame temporário é criado, contendo o nome do ator e as colunas de `Meta_score`, `No_of_Votes` e incluindo um novo TopN referente a quantidade de filmes realizados, com a ideia de amenizar o impacto de atores que realizaram poucos filmes porém bem avaliados e vice-versa.\n",
    "- Em seguida, essas colunas são renomeadas para padronizar o nome do ator para `Ator`.\n",
    "- Por fim, todos os DataFrames temporários são concatenados em um único DataFrame chamado `atores_df`, e as linhas com valores ausentes são removidas.\n",
    "- Logo mais, calcula-se as métricas de forma semelhante à função `fe_directors` criando colunas para os TopNs atores em cada métrica iterando sob cada ator e preenchendo cada coluna com a quantidade de atores referentes a cada TopN, por exemplo:\n",
    "> Para a métrica Meta Score vamos pegar o filme The Godfather com Marlon Brandon e Al Pacino como estrelas, onde ambos os atores são top10 Meta Score, logo a coluna ficaria com o 2, indicando que tal filme tem 2 atores top10 dentre as 4 estrelas presentes no filme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6793c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe_actors(train_df, test_df):\n",
    "    # Feature Engineering da coluna 'Actors'\n",
    "\n",
    "    atores = []\n",
    "\n",
    "    for col in ['Star1', 'Star2', 'Star3', 'Star4']:\n",
    "        temp_df = train_df[[col, 'Meta_score', 'No_of_Votes']].copy()\n",
    "        temp_df.columns = ['Ator', 'Meta_score', 'No_of_Votes']\n",
    "        atores.append(temp_df)\n",
    "\n",
    "    atores_df = pd.concat(atores).dropna()\n",
    "\n",
    "    # Calcular médias e quantidade de filmes por ator\n",
    "    ator_metascore = atores_df.groupby('Ator')['Meta_score'].mean()\n",
    "    ator_votes = atores_df.groupby('Ator')['No_of_Votes'].mean()\n",
    "    ator_filmes = atores_df.groupby('Ator').size()\n",
    "\n",
    "    # Top atores usando loop\n",
    "    top_n = [10, 25, 50]\n",
    "\n",
    "    # Dicionários para guardar os tops\n",
    "    top_metascore = {}\n",
    "    top_votes = {}\n",
    "    top_filmcount = {}\n",
    "\n",
    "    for n in top_n:\n",
    "        top_metascore[n] = set(ator_metascore.nlargest(n).index)\n",
    "        top_votes[n] = set(ator_votes.nlargest(n).index)\n",
    "        top_filmcount[n] = set(ator_filmes.nlargest(n).index)\n",
    "\n",
    "    # Função para contar\n",
    "    def top_atores(row, top_set):\n",
    "        atores = [row['Star1'], row['Star2'], row['Star3'], row['Star4']]\n",
    "        return sum(1 for ator in atores if ator in top_set)\n",
    "\n",
    "    for n in top_n:\n",
    "        train_df[f'top{n}_atores_metascore'] = train_df.apply(lambda x: top_atores(x, top_metascore[n]), axis=1)\n",
    "        train_df[f'top{n}_atores_votes'] = train_df.apply(lambda x: top_atores(x, top_votes[n]), axis=1)\n",
    "        train_df[f'top{n}_atores_filmes'] = train_df.apply(lambda x: top_atores(x, top_filmcount[n]), axis=1)\n",
    "\n",
    "    for n in top_n:\n",
    "        test_df[f'top{n}_atores_metascore'] = test_df.apply(lambda x: top_atores(x, top_metascore[n]), axis=1)\n",
    "        test_df[f'top{n}_atores_votes'] = test_df.apply(lambda x: top_atores(x, top_votes[n]), axis=1)\n",
    "        test_df[f'top{n}_atores_filmes'] = test_df.apply(lambda x: top_atores(x, top_filmcount[n]), axis=1)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e6eeb",
   "metadata": {},
   "source": [
    "## 7. Função para salvamento e preparo das bases de treino e teste\n",
    "- Salva a base de treino processada em `../data/train/data_train_model.csv`\n",
    "- Salva a base de teste processada em `../data/test/data_test_model.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b7a07f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_e_salvar_dados(train_df, test_df, drop_cols):\n",
    "    # Guardando títulos para referência\n",
    "    train_titles = train_df['Series_Title'].reset_index(drop=True)\n",
    "    test_titles = test_df['Series_Title'].reset_index(drop=True)\n",
    "\n",
    "    # Definindo as features e o target\n",
    "    X_train = train_df.drop(drop_cols, axis=1).reset_index(drop=True)  \n",
    "    y_train = train_df['IMDB_Rating'].reset_index(drop=True)                 \n",
    "\n",
    "    X_test = test_df.drop(drop_cols, axis=1).reset_index(drop=True)    \n",
    "    y_test = test_df['IMDB_Rating'].reset_index(drop=True)                  \n",
    "\n",
    "    # Verificando o shape dos datasets\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "    # Verificando se há valores nulos nas features\n",
    "    print(f\"\\nValores nulos em X_train: {X_train.isnull().sum().sum()}\")\n",
    "    print(f\"Valores nulos em X_test: {X_test.isnull().sum().sum()}\")\n",
    "\n",
    "    # Verificando se há valores nulos na target\n",
    "    print(f\"\\nValores nulos em y_train: {y_train.isnull().sum()}\")\n",
    "    print(f\"Valores nulos em y_test: {y_test.isnull().sum()}\")\n",
    "\n",
    "    # Verificando as colunas\n",
    "    print(f\"Quantidade de colunas em X_train: {X_train.shape[1]}\")\n",
    "    print(f\"Colunas em X_train: {X_train.columns.tolist()}\")\n",
    "\n",
    "    df_train_model = X_train.copy()\n",
    "    df_train_model['IMDB_Rating'] = y_train\n",
    "    df_train_model.to_csv('../data/train/data_train_model.csv', index=False)\n",
    "\n",
    "    df_test_model = X_test.copy()\n",
    "    df_test_model['IMDB_Rating'] = y_test\n",
    "    df_test_model.to_csv('../data/test/data_test_model.csv', index=False)\n",
    "\n",
    "    return train_titles, test_titles, X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b8c9ff",
   "metadata": {},
   "source": [
    "## 8. Pipeline de processamento de dados\n",
    "- Pipeline que centraliza as funções de criação de features e salvamento dos dados\n",
    "- Ordem das suas tarefas segue como:\n",
    "> `fe_genre()` -> `train_test_split()` -> `fe_directors()` -> `fe_actors()` -> `preparar_e_salvar_dados()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7b594172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de Feature Engineering\n",
    "\n",
    "def pipeline_feature_engineering(df, drop_cols):\n",
    "    # Cadeia de transformações\n",
    "    df_processed = fe_genre(df.copy())\n",
    "    \n",
    "    train_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Aplicando transformações nos datasets divididos\n",
    "    train_df, test_df = fe_directors(train_df.copy(), test_df.copy())\n",
    "    train_df, test_df = fe_actors(train_df, test_df)\n",
    "    \n",
    "    train_df.head()\n",
    "\n",
    "    # Preparação final\n",
    "    results = preparar_e_salvar_dados(train_df, test_df, drop_cols)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21338068",
   "metadata": {},
   "source": [
    "## 9. Definindo os espaços de busca do algoritmo de otimização de hiperparâmetros\n",
    "- Definindo os parâmetros a serem otimizados e o espaço de busca de cada um, ou seja, quais valores de cada parâmetros serão estudados com foco em encontrar os melhores parâmetros para cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "75a88624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo espaço de busca para otimização de hiperparâmetros\n",
    "\n",
    "def espaco_busca_lr(trial):\n",
    "    # Espaço de busca para regressão linear\n",
    "    return {\n",
    "        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "    }\n",
    "\n",
    "def espaco_busca_rf(trial):\n",
    "    # Espaço de busca para o random forest\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'random_state': 42 \n",
    "    }\n",
    "\n",
    "def espaco_busca_xgb(trial):\n",
    "    # Espaço de busca para o XGBoost\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 400, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, step=0.01),\n",
    "        'random_state': 42,\n",
    "        'eval_metric': 'rmse'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f748b6",
   "metadata": {},
   "source": [
    "## 10. Dicionário de configuração dos modelos\n",
    "- Dicionário que consta cada modelo e seu espaço de busca\n",
    "- Visa seguir boas práticas e tornar o código mais limpo e de fácil entendimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7ec6c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos utilizados e seus respectivos espaços de busca\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"LinearRegression\": {\n",
    "        \"classe_modelo\": LinearRegression,\n",
    "        \"espaco_busca_modelo\": espaco_busca_lr\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"classe_modelo\": RandomForestRegressor,\n",
    "        \"espaco_busca_modelo\": espaco_busca_rf\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"classe_modelo\": XGBRegressor,\n",
    "        \"espaco_busca_modelo\": espaco_busca_xgb\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8707366",
   "metadata": {},
   "source": [
    "## 11. Função `objetive`\n",
    "- Define o objeto de estudo do algoritmo de otimização de hiperparâmetros\n",
    "- Validação cruzada utilizando `KFold`\n",
    "- Criação da pipeline de pré-processamento utilizando algoritmos de transformação de variáveis:\n",
    "    - `StandarScaler()` para variáveis numéricas, visando padronizar os dados numéricos:\n",
    "            $$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "        **Onde:**\n",
    "\n",
    "        * **$x$**: é o valor original do dado.\n",
    "        * **$\\mu$**: é a média dos dados.\n",
    "        * **$\\sigma$**: é o desvio padrão dos dados.\n",
    "        * **$z$**: é o valor padronizado.\n",
    "    \n",
    "    - `OneHotEncoder` para variáveis categóricas, buscando criar colunas booleanas que agreguem informação ao modelo acerca das diferentes categorias presentes nas colunas categóricas\n",
    "\n",
    "- Pipeline de pré-processamento + algoritmo de machine learning\n",
    "- `cross_val_score` com foco em extrair as metricas de cada modelo no processo de validação\n",
    "- Cálculo do RMSE - métrica a ser otimizada pelo `optuna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e77fc67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, classe_modelo, espaco_busca, X_train, y_train, cat_cols, num_cols):\n",
    "    \n",
    "    # Definindo o KFold para validação cruzada dos modelos\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    # Configurando o espaço de busca e o modelo\n",
    "    params = espaco_busca(trial)\n",
    "    model = classe_modelo(**params)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', 'passthrough', num_cols),\n",
    "                ('cat', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), cat_cols)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "\n",
    "    # Avaliando o modelo com validação cruzada\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "    # Valor de referência a ser otimizado\n",
    "    mse_medio = -scores.mean()\n",
    "    \n",
    "    return mse_medio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a50f21",
   "metadata": {},
   "source": [
    "12. Função de treinamento e otimização de hiperparâmetros\n",
    "- A função `treinar_e_otimizar_modelos` é responsável por automatizar o fluxo de trabalho de treinamento de modelos.\n",
    "- Inicialmente, ela executa o pipeline de **Feature Engineering** (`pipeline_feature_engineering`) para preparar os dados, dividindo-os em conjuntos de treino e teste.\n",
    "- Em seguida, a função itera sobre cada modelo definido em `MODEL_CONFIG`.\n",
    "- Para cada modelo, um estudo **Optuna** é criado para otimização de hiperparâmetros, onde a função `objective` é chamada para encontrar a melhor combinação de parâmetros, minimizando a métrica de erro (RMSE).\n",
    "- Com os melhores parâmetros encontrados, a função treina uma **pipeline final**, que inclui o pré-processamento (`ColumnTransformer`) e o modelo (`regressor`), usando todo o conjunto de dados de treino.\n",
    "- Por fim, o modelo treinado é avaliado no conjunto de teste, e suas métricas (`R2` e `RMSE`) são calculadas e exibidas para comparar o desempenho de cada modelo.\n",
    "- A função retorna os modelos treinados, os melhores parâmetros e os resultados da avaliação no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "82d4b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otimização de hiperparâmetros utilizando a função otimizacao e objective no optuna, treinamento e avaliação dos modelos\n",
    "\n",
    "def treinar_e_otimizar_modelos(MODEL_CONFIG, df_original, drop_cols, num_cols, cat_cols, n_trials=15):\n",
    "\n",
    "    modelos_treinados = {}\n",
    "    best_params = {}\n",
    "    resultados_test = {}\n",
    "    \n",
    "    # Executando o pipeline de FE\n",
    "    train_titles, test_titles, X_train, y_train, X_test, y_test = pipeline_feature_engineering(\n",
    "        df_original, drop_cols\n",
    "    )\n",
    "    print(f\"FE concluído. Shape treino: {X_train.shape}, Shape teste: {X_test.shape}\")\n",
    "\n",
    "    for nome_modelo, config in MODEL_CONFIG.items():\n",
    "        # Criando estudo Optuna\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "\n",
    "        # Função objective com as configurações do modelo e dados de treinamento para validação cruzada\n",
    "        objective_dados = partial(\n",
    "            objective,\n",
    "            classe_modelo=config['classe_modelo'],\n",
    "            espaco_busca=config['espaco_busca_modelo'],\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            cat_cols=cat_cols,\n",
    "            num_cols=num_cols\n",
    "        )\n",
    "        \n",
    "        # Otimização de hiperparÇametros\n",
    "        study.optimize(objective_dados, n_trials=n_trials)\n",
    "        best_params[nome_modelo] = study.best_params\n",
    "        print(f\"Melhores parâmetros {nome_modelo}: {study.best_params}\")\n",
    "\n",
    "        # Treinando modelo final com melhores parâmetros\n",
    "        modelo_final = config['classe_modelo'](**study.best_params)\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', 'passthrough', num_cols),\n",
    "                ('cat', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), cat_cols)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', modelo_final)\n",
    "        ])\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        modelos_treinados[nome_modelo] = pipeline\n",
    "\n",
    "        # Avaliando no conjunto de teste\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        resultados_test[nome_modelo] = {\n",
    "            'R2': r2_score(y_test, y_pred),\n",
    "            'RMSE': mean_squared_error(y_test, y_pred, squared=False)\n",
    "        }\n",
    "\n",
    "        print(f\"Métricas no teste {nome_modelo}: {resultados_test[nome_modelo]}\")\n",
    "\n",
    "    # Comparando os resultados dos modelos\n",
    "    print(\"\\nResultados dos modelos no conjunto de teste:\")\n",
    "\n",
    "    for nome_modelo, metrics in resultados_test.items():\n",
    "        print(f\"{nome_modelo}: R2 = {metrics['R2']:.4f}, RMSE = {metrics['RMSE']:.4f}\")\n",
    "        print(f\"Melhores parâmetros: {best_params[nome_modelo]}\")\n",
    "\n",
    "    print(\"\\nTreinamento e otimização concluídos.\")\n",
    "    \n",
    "    dados_processados = {\n",
    "        'train_titles': train_titles,\n",
    "        'test_titles': test_titles,\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "    return modelos_treinados, best_params, resultados_test, dados_processados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95bcba3",
   "metadata": {},
   "source": [
    "## 14. Avaliação e Comparação dos Modelos\n",
    "\n",
    "- Esta etapa é crucial para entender qual modelo teve o melhor desempenho\n",
    "- Os resultados obtidos no conjunto de teste são comparados para identificar o modelo mais robusto e com maior capacidade de generalização\n",
    "\n",
    "    * **R2 (Coeficiente de Determinação):** Mede a proporção da variância na variável dependente que é previsível a partir das variáveis independentes. Quanto mais próximo de 1, melhor o modelo se ajusta aos dados.\n",
    "    * **RMSE (Root Mean Square Error):** Avalia a diferença média entre os valores previstos e os valores reais. É uma medida de erro, onde valores mais baixos indicam melhor desempenho.\n",
    "\n",
    "- É possível visualizar, também, a melhor configuração de hiperparâmetro para cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9ca2ef18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-06 16:13:49,271] A new study created in memory with name: no-name-d8732362-4bba-4837-9a83-20ffd93c421d\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,322] Trial 0 finished with value: 0.04846320939999391 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 0.04846320939999391.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,347] Trial 1 finished with value: 0.03792708478189042 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.03792708478189042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de gêneros únicos na base: 21\n",
      "\n",
      "Gêneros presentes na base:['Crime' 'Action' 'Biography' 'Drama' 'Western' 'Comedy' 'Adventure'\n",
      " 'Animation' 'Horror' 'Mystery' 'Film-Noir' 'Family' 'Romance' 'Sci-Fi'\n",
      " 'War' 'Music' 'Thriller' 'Musical' 'Fantasy' 'Sport' 'History']\n",
      "\n",
      "Shape do dataframe: (712, 35)\n",
      "\n",
      "Colunas do novo dataframe: Index(['Series_Title', 'Released_Year', 'Certificate', 'Runtime',\n",
      "       'IMDB_Rating', 'Overview', 'Meta_score', 'Director', 'Star1', 'Star2',\n",
      "       'Star3', 'Star4', 'No_of_Votes', 'Gross', 'Crime', 'Action',\n",
      "       'Biography', 'Drama', 'Western', 'Comedy', 'Adventure', 'Animation',\n",
      "       'Horror', 'Mystery', 'Film-Noir', 'Family', 'Romance', 'Sci-Fi', 'War',\n",
      "       'Music', 'Thriller', 'Musical', 'Fantasy', 'Sport', 'History'],\n",
      "      dtype='object')\n",
      "\n",
      "X_train shape: (569, 42)\n",
      "y_train shape: (569,)\n",
      "X_test shape: (143, 42)\n",
      "y_test shape: (143,)\n",
      "\n",
      "Valores nulos em X_train: 0\n",
      "Valores nulos em X_test: 0\n",
      "\n",
      "Valores nulos em y_train: 0\n",
      "Valores nulos em y_test: 0\n",
      "Quantidade de colunas em X_train: 42\n",
      "Colunas em X_train: ['Released_Year', 'Certificate', 'Runtime', 'Meta_score', 'No_of_Votes', 'Gross', 'Crime', 'Action', 'Biography', 'Drama', 'Western', 'Comedy', 'Adventure', 'Animation', 'Horror', 'Mystery', 'Film-Noir', 'Family', 'Romance', 'Sci-Fi', 'War', 'Music', 'Thriller', 'Musical', 'Fantasy', 'Sport', 'History', 'top10_dir_metascore', 'top10_dir_no_of_votes', 'top25_dir_metascore', 'top25_dir_no_of_votes', 'top50_dir_metascore', 'top50_dir_no_of_votes', 'top10_atores_metascore', 'top10_atores_votes', 'top10_atores_filmes', 'top25_atores_metascore', 'top25_atores_votes', 'top25_atores_filmes', 'top50_atores_metascore', 'top50_atores_votes', 'top50_atores_filmes']\n",
      "FE concluído. Shape treino: (569, 42), Shape teste: (143, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,375] Trial 2 finished with value: 0.04846320939999391 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,405] Trial 3 finished with value: 0.03792708478189042 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,435] Trial 4 finished with value: 0.03792708478189042 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,461] Trial 5 finished with value: 0.04846320939999391 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,484] Trial 6 finished with value: 0.04846320939999391 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,515] Trial 7 finished with value: 0.04846320939999391 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,558] Trial 8 finished with value: 0.04846320939999391 and parameters: {'fit_intercept': False}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,588] Trial 9 finished with value: 0.03792708478189042 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,610] Trial 10 finished with value: 0.03792708478189042 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,631] Trial 11 finished with value: 0.03792708478189042 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,651] Trial 12 finished with value: 0.03792708478189042 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,673] Trial 13 finished with value: 0.03792708478189042 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,693] Trial 14 finished with value: 0.03792708478189042 and parameters: {'fit_intercept': True}. Best is trial 1 with value: 0.03792708478189042.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:49,701] A new study created in memory with name: no-name-bf97b67b-7053-4140-877b-bda3c475dbb2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros LinearRegression: {'fit_intercept': True}\n",
      "Métricas no teste LinearRegression: {'R2': 0.5850022623896449, 'RMSE': 0.18644698600676912}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:53,469] Trial 0 finished with value: 0.03235907688078857 and parameters: {'n_estimators': 700, 'max_depth': 29, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:56,714] Trial 1 finished with value: 0.03673974846610234 and parameters: {'n_estimators': 900, 'max_depth': 20, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:13:59,949] Trial 2 finished with value: 0.03260281444139634 and parameters: {'n_estimators': 700, 'max_depth': 12, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:00,268] Trial 3 finished with value: 0.03787917586075023 and parameters: {'n_estimators': 100, 'max_depth': 5, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:02,151] Trial 4 finished with value: 0.03543509015507223 and parameters: {'n_estimators': 500, 'max_depth': 20, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:05,460] Trial 5 finished with value: 0.033522927581206154 and parameters: {'n_estimators': 800, 'max_depth': 28, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:07,773] Trial 6 finished with value: 0.03475641602908456 and parameters: {'n_estimators': 600, 'max_depth': 24, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:10,395] Trial 7 finished with value: 0.03598497512614086 and parameters: {'n_estimators': 700, 'max_depth': 30, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:12,594] Trial 8 finished with value: 0.036789436635449944 and parameters: {'n_estimators': 600, 'max_depth': 19, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:16,955] Trial 9 finished with value: 0.03352168297917068 and parameters: {'n_estimators': 1000, 'max_depth': 19, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:18,523] Trial 10 finished with value: 0.03237173858813888 and parameters: {'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:20,171] Trial 11 finished with value: 0.03237173858813888 and parameters: {'n_estimators': 300, 'max_depth': 12, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:21,936] Trial 12 finished with value: 0.033034999217324744 and parameters: {'n_estimators': 400, 'max_depth': 12, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:22,732] Trial 13 finished with value: 0.03375436887131739 and parameters: {'n_estimators': 200, 'max_depth': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.03235907688078857.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:24,571] Trial 14 finished with value: 0.03301353424942579 and parameters: {'n_estimators': 400, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.03235907688078857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros RandomForest: {'n_estimators': 700, 'max_depth': 29, 'min_samples_leaf': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:26,213] A new study created in memory with name: no-name-00e717a6-6ad6-4848-9e0d-867b83fcff55\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas no teste RandomForest: {'R2': 0.6072058505061297, 'RMSE': 0.1813906962912218}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-06 16:14:26,657] Trial 0 finished with value: 0.038703725148186895 and parameters: {'n_estimators': 350, 'max_depth': 17, 'learning_rate': 0.3}. Best is trial 0 with value: 0.038703725148186895.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:27,282] Trial 1 finished with value: 0.0409994757101935 and parameters: {'n_estimators': 100, 'max_depth': 29, 'learning_rate': 0.13}. Best is trial 0 with value: 0.038703725148186895.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:27,988] Trial 2 finished with value: 0.04109336275992715 and parameters: {'n_estimators': 250, 'max_depth': 20, 'learning_rate': 0.12}. Best is trial 0 with value: 0.038703725148186895.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:28,463] Trial 3 finished with value: 0.038386162032727544 and parameters: {'n_estimators': 350, 'max_depth': 29, 'learning_rate': 0.3}. Best is trial 3 with value: 0.038386162032727544.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:29,045] Trial 4 finished with value: 0.04099747201535516 and parameters: {'n_estimators': 400, 'max_depth': 25, 'learning_rate': 0.19}. Best is trial 3 with value: 0.038386162032727544.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:29,635] Trial 5 finished with value: 0.040976387015463404 and parameters: {'n_estimators': 350, 'max_depth': 15, 'learning_rate': 0.12}. Best is trial 3 with value: 0.038386162032727544.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:30,244] Trial 6 finished with value: 0.04014611690292332 and parameters: {'n_estimators': 350, 'max_depth': 28, 'learning_rate': 0.16}. Best is trial 3 with value: 0.038386162032727544.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:30,623] Trial 7 finished with value: 0.040463074772208195 and parameters: {'n_estimators': 250, 'max_depth': 16, 'learning_rate': 0.23}. Best is trial 3 with value: 0.038386162032727544.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:31,084] Trial 8 finished with value: 0.04069634644049767 and parameters: {'n_estimators': 350, 'max_depth': 14, 'learning_rate': 0.16}. Best is trial 3 with value: 0.038386162032727544.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:31,577] Trial 9 finished with value: 0.041581294748909266 and parameters: {'n_estimators': 400, 'max_depth': 25, 'learning_rate': 0.24000000000000002}. Best is trial 3 with value: 0.038386162032727544.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:32,104] Trial 10 finished with value: 0.03851812428739081 and parameters: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.03}. Best is trial 3 with value: 0.038386162032727544.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:32,413] Trial 11 finished with value: 0.04113425812425311 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.01}. Best is trial 3 with value: 0.038386162032727544.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:32,746] Trial 12 finished with value: 0.034594498413976785 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.03}. Best is trial 12 with value: 0.034594498413976785.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:33,001] Trial 13 finished with value: 0.03323976089479383 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.060000000000000005}. Best is trial 13 with value: 0.03323976089479383.\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-09-06 16:14:33,251] Trial 14 finished with value: 0.03323976089479383 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.060000000000000005}. Best is trial 13 with value: 0.03323976089479383.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros XGBoost: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.060000000000000005}\n",
      "Métricas no teste XGBoost: {'R2': 0.5446614571006329, 'RMSE': 0.19529886051069925}\n",
      "\n",
      "Resultados dos modelos no conjunto de teste:\n",
      "LinearRegression: R2 = 0.5850, RMSE = 0.1864\n",
      "Melhores parâmetros: {'fit_intercept': True}\n",
      "RandomForest: R2 = 0.6072, RMSE = 0.1814\n",
      "Melhores parâmetros: {'n_estimators': 700, 'max_depth': 29, 'min_samples_leaf': 1}\n",
      "XGBoost: R2 = 0.5447, RMSE = 0.1953\n",
      "Melhores parâmetros: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.060000000000000005}\n",
      "\n",
      "Treinamento e otimização concluídos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "modelos, params, resultados, dados = treinar_e_otimizar_modelos(\n",
    "    MODEL_CONFIG, \n",
    "    df,    \n",
    "    drop_cols,        \n",
    "    num_cols,       \n",
    "    cat_cols,       \n",
    "    n_trials=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9278bc",
   "metadata": {},
   "source": [
    "## 15. Selecionando o melhor modelo e extraindo um .csv com as previsões para cada filme na base de teste\n",
    "- Seleção do Modelo: O modelo **Random Forest** é escolhido como o \"melhor modelo\" com base em sua performance superior, identificada na etapa de avaliação anterior.\n",
    "- Previsões: O modelo selecionado faz previsões (`y_pred`) no conjunto de dados de teste.\n",
    "- Comparação e Exportação: As previsões são organizadas em um DataFrame junto com o valor real do `IMDB_Real` e o nome do filme. A coluna de previsão (`IMDB_Previsto`) é arredondada para uma casa decimal para maior legibilidade. Por fim, o DataFrame é exportado para um arquivo CSV (`imdb_rating_pred.csv`) na pasta `../data/predicted/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1e91b345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Filme  IMDB_Real  IMDB_Previsto\n",
      "0    Star Trek Into Darkness        7.7            7.8\n",
      "1               Kaze tachinu        7.8            7.9\n",
      "2                  Gully Boy        8.0            8.0\n",
      "3            The Incredibles        8.0            7.9\n",
      "4                  Cast Away        7.8            7.8\n",
      "..                       ...        ...            ...\n",
      "138           Doctor Zhivago        8.0            7.9\n",
      "139       Back to the Future        8.5            8.4\n",
      "140      There Will Be Blood        8.2            7.9\n",
      "141     (500) Days of Summer        7.7            7.8\n",
      "142                   WALL·E        8.4            8.1\n",
      "\n",
      "[143 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaop\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_model = modelos['RandomForest']\n",
    "def comparar_imdb_previsto(best_model, dados_processados, nomes_filmes_col='test_titles'):\n",
    "    # Dados de teste\n",
    "    X_test = dados_processados['X_test']\n",
    "    y_test = dados_processados['y_test']\n",
    "    test_titles = dados_processados[nomes_filmes_col]\n",
    "\n",
    "    # Previsões\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Cria o DataFrame\n",
    "    df_plot = pd.DataFrame({\n",
    "        'Filme': test_titles,\n",
    "        'IMDB_Real': y_test,\n",
    "        'IMDB_Previsto': y_pred\n",
    "    })\n",
    "    \n",
    "    # Arredonda a coluna 'IMDB_Previsto' para 1 casa decimal\n",
    "    df_plot['IMDB_Previsto'] = df_plot['IMDB_Previsto'].round(1)\n",
    "\n",
    "    # Exportando para csv\n",
    "    df_plot.to_csv(\"../data/predicted/imdb_rating_pred.csv\", sep=\";\")\n",
    "    \n",
    "    # Exibe o DataFrame\n",
    "    print(df_plot)\n",
    "\n",
    "# Chame a função para criar e mostrar o DataFrame com os valores arredondados\n",
    "comparar_imdb_previsto(best_model, dados, nomes_filmes_col='test_titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variaveis do filme Shawshank Redemption\n",
    "\n",
    "filme = {'Series_Title': 'The Shawshank Redemption',\n",
    "        'Released_Year': '1994',\n",
    "        'Certificate': 'A',\n",
    "        'Runtime': '142 min',\n",
    "        'Genre': 'Drama',\n",
    "        'Overview': 'Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.',\n",
    "        'Meta_score': 80.0,\n",
    "        'Director': 'Frank Darabont',\n",
    "        'Star1': 'Tim Robbins',\n",
    "        'Star2': 'Morgan Freeman',\n",
    "        'Star3': 'Bob Gunton',\n",
    "        'Star4': 'William Sadler',\n",
    "        'No_of_Votes': 2343110,\n",
    "        'Gross': '28,341,469'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8a599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\joaop\\AppData\\Local\\Temp\\ipykernel_4392\\1955653615.py:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  joblib.dump(best_model, \"..\\models\\RandomForest.pkl\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['..\\\\models\\\\RandomForest.pkl']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exportando melhor modelo para .pkl\n",
    "joblib.dump(best_model, \"..\\models\\RandomForest.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8965bf8",
   "metadata": {},
   "source": [
    "## 16. Função de predição de `IMDB_Rating` para novos filmes\n",
    "\n",
    "- **Carregamento do Modelo:** O modelo **Random Forest** previamente treinado é carregado do arquivo `RandomForest.pkl` utilizando a biblioteca `joblib`.\n",
    "- **Preparação dos Dados:** Uma função, `prever_imdb_rating`, é criada para receber os dados de um filme (como um dicionário) e prepará-los para a previsão. Isso inclui a conversão dos dados para um formato de DataFrame e a aplicação das transformações numéricas necessárias com a função `conv_numerico`.\n",
    "- **Execução da Previsão:** O modelo carregado (`melhor_modelo`) é usado para prever o `IMDB_Rating` do filme preparado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a97616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB previsto para o filme The Shawshank Redemption é: 8.8\n",
      "O real valor da nota IMDB do filme é 9.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_Title</th>\n",
       "      <th>Released_Year</th>\n",
       "      <th>Certificate</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Overview</th>\n",
       "      <th>Meta_score</th>\n",
       "      <th>Director</th>\n",
       "      <th>Star1</th>\n",
       "      <th>Star2</th>\n",
       "      <th>Star3</th>\n",
       "      <th>Star4</th>\n",
       "      <th>No_of_Votes</th>\n",
       "      <th>Gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>A</td>\n",
       "      <td>142</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Two imprisoned men bond over a number of years...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>Tim Robbins</td>\n",
       "      <td>Morgan Freeman</td>\n",
       "      <td>Bob Gunton</td>\n",
       "      <td>William Sadler</td>\n",
       "      <td>2343110</td>\n",
       "      <td>28341469.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Series_Title  Released_Year Certificate  Runtime  Genre  \\\n",
       "0  The Shawshank Redemption           1994           A      142  Drama   \n",
       "\n",
       "                                            Overview  Meta_score  \\\n",
       "0  Two imprisoned men bond over a number of years...        80.0   \n",
       "\n",
       "         Director        Star1           Star2       Star3           Star4  \\\n",
       "0  Frank Darabont  Tim Robbins  Morgan Freeman  Bob Gunton  William Sadler   \n",
       "\n",
       "   No_of_Votes       Gross  \n",
       "0      2343110  28341469.0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prevendo IMDB_Rating de filmes\n",
    "\n",
    "melhor_modelo = joblib.load(\"../models/RandomForest.pkl\")\n",
    "\n",
    "# Prevendo IMDB_Rating de filmes\n",
    "\n",
    "melhor_modelo = joblib.load(\"../models/RandomForest.pkl\")\n",
    "\n",
    "def prever_imdb_rating(filme, melhor_modelo):\n",
    "    melhor_modelo = modelos['RandomForest']\n",
    "    \n",
    "    df_filme = pd.DataFrame([filme])\n",
    "    df_filme = conv_numerico(df_filme)\n",
    "    imdb_rating_pred = melhor_modelo.predict(df_filme)\n",
    "    \n",
    "    # A linha abaixo foi corrigida para pegar apenas o valor do título\n",
    "    titulo_filme = df_filme['Series_Title'].iloc[0]\n",
    "    \n",
    "    print(f\"IMDB previsto para o filme {titulo_filme} é: {imdb_rating_pred[0]:.1f}\\nO real valor da nota IMDB do filme é 9.3\")\n",
    "    \n",
    "\n",
    "    return df_filme\n",
    "\n",
    "prever_imdb_rating(filme,melhor_modelo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
